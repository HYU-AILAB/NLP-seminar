{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WjDdziEN_VCt"
   },
   "source": [
    "# Dense Passage Retrieval 코드 (in-batch version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1NWluWk3_VCu"
   },
   "source": [
    "## 1. Install packages and Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "eGqFS4EEBF_Z",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/minj/anaconda3/lib/python3.8/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/home/minj/anaconda3/lib/python3.8/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Requirement already satisfied: datasets in ./anaconda3/lib/python3.8/site-packages (1.16.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in ./.local/lib/python3.8/site-packages (from datasets) (2.23.0)\n",
      "Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in ./.local/lib/python3.8/site-packages (from datasets) (6.0.0)\n",
      "Requirement already satisfied: xxhash in ./anaconda3/lib/python3.8/site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: multiprocess in ./anaconda3/lib/python3.8/site-packages (from datasets) (0.70.12.2)\n",
      "Requirement already satisfied: packaging in ./.local/lib/python3.8/site-packages (from datasets) (21.0)\n",
      "Requirement already satisfied: aiohttp in ./anaconda3/lib/python3.8/site-packages (from datasets) (3.8.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in ./anaconda3/lib/python3.8/site-packages (from datasets) (0.2.1)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in ./anaconda3/lib/python3.8/site-packages (from datasets) (4.62.3)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in ./anaconda3/lib/python3.8/site-packages (from datasets) (2021.11.1)\n",
      "Requirement already satisfied: numpy>=1.17 in ./anaconda3/lib/python3.8/site-packages (from datasets) (1.21.4)\n",
      "Requirement already satisfied: dill in ./anaconda3/lib/python3.8/site-packages (from datasets) (0.3.4)\n",
      "Requirement already satisfied: pandas in ./anaconda3/lib/python3.8/site-packages (from datasets) (1.1.5)\n",
      "Requirement already satisfied: pyyaml in ./.local/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.local/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.0.1)\n",
      "Requirement already satisfied: filelock in ./anaconda3/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.0.12)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in ./.local/lib/python3.8/site-packages (from packaging->datasets) (2.4.7)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in ./.local/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in ./.local/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.local/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in ./.local/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (1.25.11)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.local/lib/python3.8/site-packages (from aiohttp->datasets) (20.3.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in ./.local/lib/python3.8/site-packages (from aiohttp->datasets) (2.0.7)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./anaconda3/lib/python3.8/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in ./anaconda3/lib/python3.8/site-packages (from aiohttp->datasets) (4.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./anaconda3/lib/python3.8/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./anaconda3/lib/python3.8/site-packages (from aiohttp->datasets) (1.7.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./anaconda3/lib/python3.8/site-packages (from aiohttp->datasets) (5.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in ./.local/lib/python3.8/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in ./anaconda3/lib/python3.8/site-packages (from pandas->datasets) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in ./anaconda3/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.16.0)\n",
      "/home/minj/anaconda3/lib/python3.8/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/home/minj/anaconda3/lib/python3.8/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Requirement already satisfied: transformers in ./anaconda3/lib/python3.8/site-packages (4.12.5)\n",
      "Requirement already satisfied: numpy>=1.17 in ./anaconda3/lib/python3.8/site-packages (from transformers) (1.21.4)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in ./anaconda3/lib/python3.8/site-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./anaconda3/lib/python3.8/site-packages (from transformers) (2020.10.15)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./anaconda3/lib/python3.8/site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.local/lib/python3.8/site-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: requests in ./.local/lib/python3.8/site-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: filelock in ./anaconda3/lib/python3.8/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: sacremoses in ./anaconda3/lib/python3.8/site-packages (from transformers) (0.0.46)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in ./anaconda3/lib/python3.8/site-packages (from transformers) (0.2.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.local/lib/python3.8/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.local/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in ./.local/lib/python3.8/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.local/lib/python3.8/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in ./.local/lib/python3.8/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in ./.local/lib/python3.8/site-packages (from requests->transformers) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in ./.local/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: joblib in ./.local/lib/python3.8/site-packages (from sacremoses->transformers) (1.1.0)\n",
      "Requirement already satisfied: click in ./.local/lib/python3.8/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: six in ./anaconda3/lib/python3.8/site-packages (from sacremoses->transformers) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "746acc13c0434148997b2be1e5e347dc",
      "e694d87aed874031a16c282b33f5c2f4",
      "169dfc0f181b4dd9bab8ea9eef8109cc",
      "1a9a0ad91a494ae2aaaeb39ea7c55182",
      "f813a93c66c9478190c4106545871b49",
      "440d4740d27f4f0595bb82b492d082b6",
      "8aabed3b5c5f4c099a7f3df1e4c4e006",
      "37d1ffffa4044912ba3fdfa2404536fe",
      "a1392ec980ab4c68a01fcaf710973499",
      "58847f46ff934a57a2f652af23227814",
      "ce610399056148c19cffca5073689e08"
     ]
    },
    "id": "4IUxepuj_VCv",
    "outputId": "1449b989-054f-43e1-f455-bf0c73ed8e24"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad_kor_v1 (/home/minj/.cache/huggingface/datasets/squad_kor_v1/squad_kor_v1/1.0.0/18d4f44736b8ee85671f63cb84965bfb583fa0a4ff2df3c2e10eee9693796725)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0092891f2404b19b2bc21798901411c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"squad_kor_v1\") # KorQuAD train 데이터셋을 학습 데이터로 활용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lJtECqpB_VCx"
   },
   "source": [
    "## 2. Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X0Fu2WaqpUB8"
   },
   "source": [
    "BERT를 encoder로 사용하므로, huggingface에서 \"klue/bert-base\" tokenizer를 받아서 사용하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AoB8BHGDmVIK",
    "outputId": "cf8a0d4a-688d-4fdd-ecc3-8a0d27fb9a83"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='klue/bert-base', vocab_size=32000, model_max_len=512, is_fast=True, padding_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "\n",
    "model_checkpoint = \"klue/bert-base\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "id": "0U7sn3jsu44O",
    "outputId": "a27b2564-64e2-45e2-f494-a46cd3fcd544"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] 1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로 해서 하나의 교향곡을 쓰려는 뜻을 갖는다. 이 시기 바그너는 1838년에 빛 독촉으로 산전수전을 다 [UNK] 상황이라 좌절과 실망에 가득했으며 메피스토펠레스를 만나는 파우스트의 심경에 공감했다고 한다. 또한 파리에서 아브네크의 지휘로 파리 음악원 관현악단이 연주하는 베토벤의 교향곡 9번을 듣고 깊은 감명을 받았는데, 이것이 이듬해 1월에 파우스트의 서곡으로 쓰여진 이 작품에 조금이라도 영향을 끼쳤으리라는 것은 의심할 여지가 없다. 여기의 라단조 조성의 경우에도 그의 전기에 적혀 있는 것처럼 단순한 정신적 피로나 실의가 반영된 것이 아니라 베토벤의 합창교향곡 조성의 영향을 받은 것을 볼 수 있다. 그렇게 교향곡 작곡을 1839년부터 40년에 걸쳐 파리에서 착수했으나 1악장을 쓴 뒤에 중단했다. 또한 작품의 완성과 동시에 그는 이 서곡 ( 1악장 ) 을 파리 음악원의 연주회에서 연주할 파트보까지 준비하였으나, 실제로는 이루어지지는 않았다. 결국 초연은 4년 반이 지난 후에 드레스덴에서 연주되었고 재연도 이루어졌지만, 이후에 그대로 방치되고 말았다. 그 사이에 그는 리엔치와 방황하는 네덜란드인을 완성하고 탄호이저에도 착수하는 등 분주한 시간을 보냈는데, 그런 바쁜 생활이 이 곡을 잊게 한 것이 아닌가 하는 의견도 있다. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_input = tokenizer(dataset['train'][0]['context'], padding=\"max_length\", truncation=True)\n",
    "tokenizer.decode(tokenized_input['input_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zpoTleVJjp5x"
   },
   "source": [
    "## 3. Dense encoder (BERT) 학습 시키기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_nrxmtmfkRVb"
   },
   "source": [
    "HuggingFace BERT를 활용하여 question encoder, passage encoder 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "6b215ZfJ_EOc"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm, trange\n",
    "import argparse\n",
    "import random\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import BertModel, BertPreTrainedModel, AdamW, TrainingArguments, get_linear_schedule_with_warmup\n",
    "\n",
    "random_seed = 42\n",
    "\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N-bKwkxTpoje"
   },
   "source": [
    "1) Training Dataset 준비하기 (question, passage pairs)\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "E_FQ1kcazxge"
   },
   "outputs": [],
   "source": [
    "# Use subset (128 example) of original training dataset \n",
    "sample_idx = np.random.choice(range(len(dataset['train'])), 128)\n",
    "training_dataset = dataset['train'][sample_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "NJZWx1b-613e"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import (DataLoader, RandomSampler, TensorDataset)\n",
    "\n",
    "q_seqs = tokenizer(training_dataset['question'], padding=\"max_length\", truncation=True, return_tensors='pt')\n",
    "p_seqs = tokenizer(training_dataset['context'], padding=\"max_length\", truncation=True, return_tensors='pt')\n",
    "\n",
    "train_dataset = TensorDataset(p_seqs['input_ids'], p_seqs['attention_mask'], p_seqs['token_type_ids'], \n",
    "                        q_seqs['input_ids'], q_seqs['attention_mask'], q_seqs['token_type_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JwMvVH1e3h99"
   },
   "source": [
    "2) BERT encoder 학습시키기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vW7Oc7Zd9kkm"
   },
   "source": [
    "BertEncoder 모델 정의 후, passage를 embedding하는 p_ encoder과 question embedding을 하는 q_encoder 각각에 pre-trained weight 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "oKKkTlh_l5VL"
   },
   "outputs": [],
   "source": [
    "class BertEncoder(BertPreTrainedModel):\n",
    "  def __init__(self, config):\n",
    "    super(BertEncoder, self).__init__(config)\n",
    "\n",
    "    self.bert = BertModel(config)\n",
    "    self.init_weights()\n",
    "      \n",
    "  def forward(self, input_ids, \n",
    "              attention_mask=None, token_type_ids=None): \n",
    "  \n",
    "      outputs = self.bert(input_ids,\n",
    "                          attention_mask=attention_mask,\n",
    "                          token_type_ids=token_type_ids)\n",
    "      \n",
    "      pooled_output = outputs[1]\n",
    "\n",
    "      return pooled_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wnO1b30SomBP",
    "outputId": "243c0cba-5afe-41e6-e452-bdd20a9ab5e1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertEncoder: ['cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertEncoder: ['cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# load pre-trained model on cuda (if available)\n",
    "p_encoder = BertEncoder.from_pretrained(model_checkpoint)\n",
    "q_encoder = BertEncoder.from_pretrained(model_checkpoint)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  p_encoder.cuda()\n",
    "  q_encoder.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f3Dgo8U997HD"
   },
   "source": [
    "Train function 정의 후, 두개의 encoder fine-tuning 하기 (In-batch negative 활용) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "VAb7NpUc8YRo"
   },
   "outputs": [],
   "source": [
    "def train(args, dataset, p_model, q_model):\n",
    "  \n",
    "  # Dataloader\n",
    "  train_sampler = RandomSampler(dataset)\n",
    "  train_dataloader = DataLoader(dataset, sampler=train_sampler, batch_size=args.per_device_train_batch_size)\n",
    "\n",
    "  # Optimizer\n",
    "  no_decay = ['bias', 'LayerNorm.weight']\n",
    "  optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in p_model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': args.weight_decay},\n",
    "        {'params': [p for n, p in p_model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0},\n",
    "        {'params': [p for n, p in q_model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': args.weight_decay},\n",
    "        {'params': [p for n, p in q_model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "        ]\n",
    "  optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, eps=args.adam_epsilon)\n",
    "  t_total = len(train_dataloader) // args.gradient_accumulation_steps * args.num_train_epochs\n",
    "  scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=args.warmup_steps, num_training_steps=t_total)\n",
    "\n",
    "  # Start training!\n",
    "  global_step = 0\n",
    "  \n",
    "  p_model.zero_grad()\n",
    "  q_model.zero_grad()\n",
    "  torch.cuda.empty_cache()\n",
    "  \n",
    "\n",
    "  for _ in trange(int(args.num_train_epochs), desc=\"Epoch\"):\n",
    "    for step, batch in enumerate(tqdm(train_dataloader, desc=\"Iteration\")):\n",
    "      q_encoder.train()\n",
    "      p_encoder.train()\n",
    "      \n",
    "      if torch.cuda.is_available():\n",
    "        batch = tuple(t.cuda() for t in batch)\n",
    "\n",
    "      p_inputs = {'input_ids': batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'token_type_ids': batch[2]\n",
    "                  }\n",
    "      \n",
    "      q_inputs = {'input_ids': batch[3],\n",
    "                  'attention_mask': batch[4],\n",
    "                  'token_type_ids': batch[5]}\n",
    "      \n",
    "      p_outputs = p_model(**p_inputs)  # (batch_size, emb_dim)\n",
    "      q_outputs = q_model(**q_inputs)  # (batch_size, emb_dim)\n",
    "\n",
    "\n",
    "      # Calculate similarity score & loss\n",
    "      sim_scores = torch.matmul(q_outputs, torch.transpose(p_outputs, 0, 1))  # (batch_size, emb_dim) x (emb_dim, batch_size) = (batch_size, batch_size)\n",
    "\n",
    "      # target: position of positive samples = diagonal element \n",
    "      targets = torch.arange(0, args.per_device_train_batch_size).long()\n",
    "      if torch.cuda.is_available():\n",
    "        targets = targets.to('cuda')\n",
    "\n",
    "      sim_scores = F.log_softmax(sim_scores, dim=1)\n",
    "\n",
    "      loss = F.nll_loss(sim_scores, targets)\n",
    "      #print(loss)\n",
    "\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      scheduler.step()\n",
    "      q_model.zero_grad()\n",
    "      p_model.zero_grad()\n",
    "      global_step += 1\n",
    "      \n",
    "      torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "    \n",
    "  return p_model, q_model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ICSJoJrUDGZ5"
   },
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=\"dense_retireval\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8, \n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E8a7ww3WgsaZ",
    "outputId": "40913940-c9f6-4022-9439-2663a1b0dc03"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "Iteration:   0%|          | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   6%|▋         | 1/16 [00:00<00:11,  1.30it/s]\u001b[A\n",
      "Iteration:  12%|█▎        | 2/16 [00:01<00:11,  1.21it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 3/16 [00:02<00:10,  1.19it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 4/16 [00:03<00:10,  1.18it/s]\u001b[A\n",
      "Iteration:  31%|███▏      | 5/16 [00:04<00:09,  1.17it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 6/16 [00:05<00:08,  1.17it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 7/16 [00:05<00:07,  1.16it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 8/16 [00:06<00:06,  1.16it/s]\u001b[A\n",
      "Iteration:  56%|█████▋    | 9/16 [00:07<00:06,  1.16it/s]\u001b[A\n",
      "Iteration:  62%|██████▎   | 10/16 [00:08<00:05,  1.16it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 11/16 [00:09<00:04,  1.16it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 12/16 [00:10<00:03,  1.16it/s]\u001b[A\n",
      "Iteration:  81%|████████▏ | 13/16 [00:11<00:02,  1.16it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 14/16 [00:11<00:01,  1.16it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 15/16 [00:12<00:00,  1.16it/s]\u001b[A\n",
      "Iteration: 100%|██████████| 16/16 [00:13<00:00,  1.17it/s]\u001b[A\n",
      "Epoch:  20%|██        | 1/5 [00:13<00:54, 13.71s/it]\n",
      "Iteration:   0%|          | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   6%|▋         | 1/16 [00:00<00:12,  1.17it/s]\u001b[A\n",
      "Iteration:  12%|█▎        | 2/16 [00:01<00:12,  1.17it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 3/16 [00:02<00:11,  1.16it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 4/16 [00:03<00:10,  1.16it/s]\u001b[A\n",
      "Iteration:  31%|███▏      | 5/16 [00:04<00:09,  1.14it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 6/16 [00:05<00:08,  1.15it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 7/16 [00:06<00:07,  1.15it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 8/16 [00:06<00:06,  1.16it/s]\u001b[A\n",
      "Iteration:  56%|█████▋    | 9/16 [00:07<00:06,  1.16it/s]\u001b[A\n",
      "Iteration:  62%|██████▎   | 10/16 [00:08<00:05,  1.16it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 11/16 [00:09<00:04,  1.14it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 12/16 [00:10<00:03,  1.14it/s]\u001b[A\n",
      "Iteration:  81%|████████▏ | 13/16 [00:11<00:02,  1.15it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 14/16 [00:12<00:01,  1.15it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 15/16 [00:13<00:00,  1.16it/s]\u001b[A\n",
      "Iteration: 100%|██████████| 16/16 [00:13<00:00,  1.15it/s]\u001b[A\n",
      "Epoch:  40%|████      | 2/5 [00:27<00:41, 13.81s/it]\n",
      "Iteration:   0%|          | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   6%|▋         | 1/16 [00:00<00:13,  1.12it/s]\u001b[A\n",
      "Iteration:  12%|█▎        | 2/16 [00:01<00:12,  1.14it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 3/16 [00:02<00:11,  1.15it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 4/16 [00:03<00:10,  1.15it/s]\u001b[A\n",
      "Iteration:  31%|███▏      | 5/16 [00:04<00:09,  1.16it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 6/16 [00:05<00:08,  1.13it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 7/16 [00:06<00:07,  1.14it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 8/16 [00:07<00:06,  1.14it/s]\u001b[A\n",
      "Iteration:  56%|█████▋    | 9/16 [00:07<00:06,  1.15it/s]\u001b[A\n",
      "Iteration:  62%|██████▎   | 10/16 [00:08<00:05,  1.15it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 11/16 [00:09<00:04,  1.15it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 12/16 [00:10<00:03,  1.13it/s]\u001b[A\n",
      "Iteration:  81%|████████▏ | 13/16 [00:11<00:02,  1.14it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 14/16 [00:12<00:01,  1.14it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 15/16 [00:13<00:00,  1.15it/s]\u001b[A\n",
      "Iteration: 100%|██████████| 16/16 [00:13<00:00,  1.15it/s]\u001b[A\n",
      "Epoch:  60%|██████    | 3/5 [00:41<00:27, 13.88s/it]\n",
      "Iteration:   0%|          | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   6%|▋         | 1/16 [00:00<00:12,  1.17it/s]\u001b[A\n",
      "Iteration:  12%|█▎        | 2/16 [00:01<00:12,  1.17it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 3/16 [00:02<00:11,  1.16it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 4/16 [00:03<00:10,  1.16it/s]\u001b[A\n",
      "Iteration:  31%|███▏      | 5/16 [00:04<00:09,  1.16it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 6/16 [00:05<00:08,  1.16it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 7/16 [00:06<00:07,  1.16it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 8/16 [00:06<00:06,  1.16it/s]\u001b[A\n",
      "Iteration:  56%|█████▋    | 9/16 [00:07<00:06,  1.16it/s]\u001b[A\n",
      "Iteration:  62%|██████▎   | 10/16 [00:08<00:05,  1.16it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 11/16 [00:09<00:04,  1.16it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 12/16 [00:10<00:03,  1.16it/s]\u001b[A\n",
      "Iteration:  81%|████████▏ | 13/16 [00:11<00:02,  1.16it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 14/16 [00:12<00:01,  1.16it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 15/16 [00:12<00:00,  1.16it/s]\u001b[A\n",
      "Iteration: 100%|██████████| 16/16 [00:13<00:00,  1.16it/s]\u001b[A\n",
      "Epoch:  80%|████████  | 4/5 [00:55<00:13, 13.84s/it]\n",
      "Iteration:   0%|          | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   6%|▋         | 1/16 [00:00<00:12,  1.16it/s]\u001b[A\n",
      "Iteration:  12%|█▎        | 2/16 [00:01<00:12,  1.16it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 3/16 [00:02<00:11,  1.16it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 4/16 [00:03<00:10,  1.16it/s]\u001b[A\n",
      "Iteration:  31%|███▏      | 5/16 [00:04<00:09,  1.16it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 6/16 [00:05<00:08,  1.16it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 7/16 [00:06<00:07,  1.16it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 8/16 [00:06<00:06,  1.16it/s]\u001b[A\n",
      "Iteration:  56%|█████▋    | 9/16 [00:07<00:06,  1.16it/s]\u001b[A\n",
      "Iteration:  62%|██████▎   | 10/16 [00:08<00:05,  1.16it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 11/16 [00:09<00:04,  1.16it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 12/16 [00:10<00:03,  1.16it/s]\u001b[A\n",
      "Iteration:  81%|████████▏ | 13/16 [00:11<00:02,  1.16it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 14/16 [00:12<00:01,  1.16it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 15/16 [00:12<00:00,  1.16it/s]\u001b[A\n",
      "Iteration: 100%|██████████| 16/16 [00:13<00:00,  1.15it/s]\u001b[A\n",
      "Epoch: 100%|██████████| 5/5 [01:09<00:00, 13.84s/it]\n"
     ]
    }
   ],
   "source": [
    "p_encoder, q_encoder = train(args, train_dataset, p_encoder, q_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BGOw-k7Ln85t"
   },
   "source": [
    "## 4. Valid set에 있는 Question에 대하여 passage retrieval를 해보자!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rt3NcfdHMYJQ"
   },
   "source": [
    "valid set을 불러오자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NouB9uBcTaws",
    "outputId": "61ffcd1d-7a1a-4374-8ba0-093ac54f17af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********[Selected Query]*********\n",
      "'지상파 3사중 유일하게 SBS만 단독중계를 하게 된 이유는 무엇때문인가?'\n",
      "\n",
      "*********[Ground Truth]*********\n",
      "('한편 대한민국 내 방송사로는 유일하게 SBS에서 단독으로 밴쿠버 올림픽 개·폐회식 및 경기 등을 생중계하였다. SBS를 제외한 나머지 '\n",
      " '지상파 방송사들은 아예 밴쿠버 현지에 취재진 등을 파견하거나 올림픽에 관한 방송을 하지 않기로 방침을 정했으나, 시청자들의 항의로 '\n",
      " 'SBS에서 제공한 2분분량의 영상으로 관련보도를 하는데 합의하였다. SBS는 IOC와의 올림픽 중계 독점계약 절차에 따라 향후 2012년 '\n",
      " '영국 런던과 2016년 브라질 리우데자네이루에서 개최되는 하계 올림픽과 2014년 러시아 소치에서 열리는 동계 올림픽에서도 올림픽 '\n",
      " '단독중계를 하게 될 예정이었다. 이에 KBS와 MBC 등 방송사들이 방송통신위원회에 공동 중계요청을 제안했으나 SBS측이 IOC와의 '\n",
      " '독점계약상에 위반된다는 이유로 이를 거부하여 결국 SBS 단독으로 올림픽 중계를 하게 되었다. 그러나 방송통신위원회의 징계로 SBS가 '\n",
      " '과징금을 물게 되어 2012년 영국 런던과 2016년 브라질 리우데자네이루에서 개최되는 하계 올림픽과 2014년 러시아 소치에서 열리는 '\n",
      " '동계 올림픽 부터 독점중계를 깨고 지상파 3사가 공동 중계하게 되었다. 한편 SBS는 올림픽 생중계 도중 스피드 스케이팅 중계 때 '\n",
      " '대한민국의 박도영 선수를 소개하는 자막에서 태극기와 대한민국(KOR)이 아닌 일본의 일장기와 일본(JPN) 국적으로 오표기를 하여 논란을 '\n",
      " '일으키기도 했다. 이에 SBS 게시판에는 항의의 글들이 쇄도했으며 SBS는 이에 대해 공식적으로 사과와 해명을 하였다.')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "valid_corpus = list(set([example['context'] for example in dataset['validation']]))[:10] # 10개 documents중에서 top k를 뽑아보자\n",
    "sample_idx = random.choice(range(len(dataset['validation'])))\n",
    "query = dataset['validation'][sample_idx]['question']\n",
    "ground_truth = dataset['validation'][sample_idx]['context']\n",
    "\n",
    "if not ground_truth in valid_corpus:\n",
    "  valid_corpus.append(ground_truth)\n",
    "\n",
    "print(f\"*********[Selected Query]*********\")\n",
    "pprint(query)\n",
    "print()\n",
    "print(f\"*********[Ground Truth]*********\")\n",
    "pprint(ground_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "05D8GzFrJhHO"
   },
   "source": [
    "앞서 학습한 passage encoder, question encoder을 이용해 dense embedding 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "ba-hH3NQOEWJ"
   },
   "outputs": [],
   "source": [
    "def to_cuda(batch):\n",
    "  return tuple(t.cuda() for t in batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YufA_ayPJBRg",
    "outputId": "0da35373-4abd-4812-e01d-cb7c6555e7b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11, 768]) torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "  p_encoder.eval()\n",
    "  q_encoder.eval()\n",
    "\n",
    "  q_seqs_val = tokenizer([query], padding=\"max_length\", truncation=True, return_tensors='pt').to('cuda')\n",
    "  q_emb = q_encoder(**q_seqs_val).to('cpu')  #(num_query, emb_dim)\n",
    "\n",
    "  p_embs = []\n",
    "  for p in valid_corpus:\n",
    "    p = tokenizer(p, padding=\"max_length\", truncation=True, return_tensors='pt').to('cuda')\n",
    "    p_emb = p_encoder(**p).to('cpu').numpy()\n",
    "    p_embs.append(p_emb)\n",
    "\n",
    "p_embs = torch.Tensor(p_embs).squeeze()  # (num_passage, emb_dim)\n",
    "\n",
    "print(p_embs.size(), q_emb.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pOHHak7WS1ko"
   },
   "source": [
    "dot product를 수행 => Document들의 유사도 ranking을 구함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xn5Cx5JkKZJB",
    "outputId": "047877d7-90d8-47b0-d73e-87a11bec6ef8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 11])\n",
      "tensor([[177.5575, 179.3276, 170.4498, 164.7650, 171.7243, 182.1234, 173.9379,\n",
      "         159.2195, 170.6320, 185.8634, 200.5819]])\n",
      "tensor([10,  9,  5,  1,  0,  6,  4,  8,  2,  3,  7])\n"
     ]
    }
   ],
   "source": [
    "dot_prod_scores = torch.matmul(q_emb, torch.transpose(p_embs, 0, 1))\n",
    "print(dot_prod_scores.size())\n",
    "\n",
    "rank = torch.argsort(dot_prod_scores, dim=1, descending=True).squeeze()\n",
    "print(dot_prod_scores)\n",
    "print(rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oq2Oiv8MKVS6"
   },
   "source": [
    "Top-5개의 passage를 retrieve 하고 ground truth와 비교하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WaStRXYdJ-wI",
    "outputId": "7c22b7fb-4ab7-48f8-8278-0dfb59929d2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********[Search query]*********\n",
      " 지상파 3사중 유일하게 SBS만 단독중계를 하게 된 이유는 무엇때문인가? \n",
      "\n",
      "*********[Ground truth passage]*********\n",
      "한편 대한민국 내 방송사로는 유일하게 SBS에서 단독으로 밴쿠버 올림픽 개·폐회식 및 경기 등을 생중계하였다. SBS를 제외한 나머지 지상파 방송사들은 아예 밴쿠버 현지에 취재진 등을 파견하거나 올림픽에 관한 방송을 하지 않기로 방침을 정했으나, 시청자들의 항의로 SBS에서 제공한 2분분량의 영상으로 관련보도를 하는데 합의하였다. SBS는 IOC와의 올림픽 중계 독점계약 절차에 따라 향후 2012년 영국 런던과 2016년 브라질 리우데자네이루에서 개최되는 하계 올림픽과 2014년 러시아 소치에서 열리는 동계 올림픽에서도 올림픽 단독중계를 하게 될 예정이었다. 이에 KBS와 MBC 등 방송사들이 방송통신위원회에 공동 중계요청을 제안했으나 SBS측이 IOC와의 독점계약상에 위반된다는 이유로 이를 거부하여 결국 SBS 단독으로 올림픽 중계를 하게 되었다. 그러나 방송통신위원회의 징계로 SBS가 과징금을 물게 되어 2012년 영국 런던과 2016년 브라질 리우데자네이루에서 개최되는 하계 올림픽과 2014년 러시아 소치에서 열리는 동계 올림픽 부터 독점중계를 깨고 지상파 3사가 공동 중계하게 되었다. 한편 SBS는 올림픽 생중계 도중 스피드 스케이팅 중계 때 대한민국의 박도영 선수를 소개하는 자막에서 태극기와 대한민국(KOR)이 아닌 일본의 일장기와 일본(JPN) 국적으로 오표기를 하여 논란을 일으키기도 했다. 이에 SBS 게시판에는 항의의 글들이 쇄도했으며 SBS는 이에 대해 공식적으로 사과와 해명을 하였다. \n",
      "\n",
      "************************************\n",
      "Top-1 passage with score 200.5819\n",
      "한편 대한민국 내 방송사로는 유일하게 SBS에서 단독으로 밴쿠버 올림픽 개·폐회식 및 경기 등을 생중계하였다. SBS를 제외한 나머지 지상파 방송사들은 아예 밴쿠버 현지에 취재진 등을 파견하거나 올림픽에 관한 방송을 하지 않기로 방침을 정했으나, 시청자들의 항의로 SBS에서 제공한 2분분량의 영상으로 관련보도를 하는데 합의하였다. SBS는 IOC와의 올림픽 중계 독점계약 절차에 따라 향후 2012년 영국 런던과 2016년 브라질 리우데자네이루에서 개최되는 하계 올림픽과 2014년 러시아 소치에서 열리는 동계 올림픽에서도 올림픽 단독중계를 하게 될 예정이었다. 이에 KBS와 MBC 등 방송사들이 방송통신위원회에 공동 중계요청을 제안했으나 SBS측이 IOC와의 독점계약상에 위반된다는 이유로 이를 거부하여 결국 SBS 단독으로 올림픽 중계를 하게 되었다. 그러나 방송통신위원회의 징계로 SBS가 과징금을 물게 되어 2012년 영국 런던과 2016년 브라질 리우데자네이루에서 개최되는 하계 올림픽과 2014년 러시아 소치에서 열리는 동계 올림픽 부터 독점중계를 깨고 지상파 3사가 공동 중계하게 되었다. 한편 SBS는 올림픽 생중계 도중 스피드 스케이팅 중계 때 대한민국의 박도영 선수를 소개하는 자막에서 태극기와 대한민국(KOR)이 아닌 일본의 일장기와 일본(JPN) 국적으로 오표기를 하여 논란을 일으키기도 했다. 이에 SBS 게시판에는 항의의 글들이 쇄도했으며 SBS는 이에 대해 공식적으로 사과와 해명을 하였다.\n",
      "\n",
      "Top-2 passage with score 185.8634\n",
      "\"서양 철학\"이라는 용어의 지정학적 경계는 19-20세기에 걸쳐 형성되었다. 이 시기 이전에 대부분의 유럽 사람들은 국가나 철학, 문화에 대해서 \"서양\"이란 개념이 없이, 서로 다른 국가와 언어, 개인, 지리학적인 지역이라고 생각했었다. 많은 세계 지도가 조잡하고 부정확했으며, 1800년대 이전에는 유럽 너머의 다른 지역의 특정한 지리적, 정치적 차이가 잘 알려지지 않았다. 정확한 지도가 매우 드물었으며, 유럽과 멀리 떨어진 지역에 사는 사람들에 대한 정확한 정보도 거의 없었다. 일부 사람들이 생각하는 것처럼, 서양 철학은 주로 유럽에서 유래한 생각으로 최근에 형성되었다. 우리가 오늘날 서양 철학이라고 생각하는 것은, 그리스-로마와 유대-기독교 문화, 르네상스, 계몽주의, 식민주의로서 일반적으로 정의된다. 때때로 \"서양 철학\"이라는 용어는 수천년간 등장한 너무나 다양하고 서로 상반되는 전통과 정치, 종교, 사상가들을 총망라하고 있는 개념이어서 쓸모없거나 의미를 이해하기 힘든 말이다.\n",
      "\n",
      "Top-3 passage with score 182.1234\n",
      "체스는 가로 8개와 세로 8개, 총 64개의 정사각형으로 이루어진 체스보드에서 이루어진다. 체스보드 위의 64개의 정사각형들은 흰색과 검은색이 번갈아가며 칠해져 있으며, 영/미식 체커보드와 매우 유사하다. 체스보드에 칠해져 있는 색이 항상 흰색과 검은색은 아니지만 언제나 서로 확실히 구분되는 밝은 색 하나와 어두운 색 하나로 이루어져 있다. 이때, 밝은 색 칸들은 \"백색\", \"밝은색\", 또는 \"옅은색\"으로 불리며 어두운 색 칸들은색\", \"어두운색\" 등으로 불린다. 각각의 선수들은 16개의 백색 또는 흑색기물을 갖고 시작한다. 체스를 두는 사람의 가장 오른쪽 아래에 위치한 정사각형이 흰색이 되도록 보드를 배치하여야 한다. 체스보드에서 \"열\"은 랭크라고 불리며 1부터 8까지의 숫자가 붙여지고 \"행\"은 파일라고 불리며 a부터 h까지의 알파벳을 붙인다.\n",
      "\n",
      "Top-4 passage with score 179.3276\n",
      "2010년 3월 26일, 백령도 근처 해상에서 대한민국 해군의 초계함인 PCC-772 천안이 침몰되는 사건이 일어났다. 대한민국 정부에서 발표한 이 사건의 공식 명칭은 \"천안함 피격 사건\"(天安艦被擊事件)이다. 북한 정찰총국 소행으로 보고 있다. 이 사건으로 대한민국 해군 병 40명이 사망했으며 6명이 실종되었다. 대한민국 정부는 천안함 침몰 원인을 규명할 민간·군인 합동조사단을 구성하였고, 대한민국을 포함한 오스트레일리아, 미국, 스웨덴, 영국 등 5개국에서 전문가 24여 명으로 구성된 합동조사단은 2010년 5월 20일 천안함이 조선민주주의인민공화국의 어뢰공격으로 침몰한 것이라고 발표하였다. 이러한 조사 결과 발표는 미국과 유럽 연합, 일본 외에 인도 등 비동맹국들의 지지를 얻어 국제 연합 안전보장이사회의 안건으로 회부되었으며. 안보리는 천안함 공격을 규탄하는 내용의 의장성명을 채택하였다. 그러나 조선민주주의인민공화국이 자신들과 관련이 전혀 없다고 주장하고, 중화인민공화국과 러시아가 반대하면서 조선민주주의인민공화국을 직접적으로 비난하는 내용에 이르지는 못했다. 조선민주주의인민공화국은 대한민국의 조사 결과에 대해 \"특대형 모략극\"이라며 사고 지점 근처에서 암초가 많다는 점을 들며 좌초한 것이라고 주장했다. 천안함의 침몰에서 인양, 조사 발표까지 대한민국 사회와 주변국의 관심을 끌었으며, 천안함의 침몰 원인을 규명하는 과정에서 언론과 각계 인사들을 통해 다수의 가설 또는 의혹들이 제기되기도 하였다. 이 사건으로 인해 남북간의 긴장이 고조되었으며, 대한민국에서는 침몰 원인에 대해 각기 다른 해석으로 갈등을 빚기도 했다.\n",
      "\n",
      "Top-5 passage with score 177.5575\n",
      "8세기에 노르드 조어가 고대 노르드어로 진화하면서, 독일어 움라우트가 노르드어 사용 지역에도 영향을 미친 것으로 보인다. 그러나 나중에 움라우트 사용이 각기 달라지기 시작하면서 서노르드어와 동노르드어가 분열하게 되었다. 보통 움라우트는 서노르드어에서 더 잘 보존되었고(예컨대 fylla 퓔라 < *fullijan), 동노르드에서는 보편화를 거쳐 움라우트들이 많이 사라졌다. 오래된 동노르드어 문헌들이나 동노르드 룬 각석들은 후기 서노르드어에서 나타나는 정도와 같은 움라우트를 보존하고 있다. 한편 이중모음화는 동노르드어에서 더욱 두드러졌다(예컨대 hiarta 히아르타 < *hertō)는데, 아마 이것도 굴절어 체계 내부의 일반화 때문으로 추측된다. 이러한 차이가 9세기에서 10세기 사이에 동서 노르드어가 분화하게 된 가장 큰 이유로서, 노르웨이와 대서양 정착지들에서는 서노르드어가, 덴마크와 스웨덴에서는 동노르드어가 쓰이게 되었다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "print(\"*********[Search query]*********\\n\", query, \"\\n\")\n",
    "print(\"*********[Ground truth passage]*********\")\n",
    "print(ground_truth, \"\\n\")\n",
    "print('************************************')\n",
    "for i in range(k):\n",
    "  print(\"Top-%d passage with score %.4f\" % (i+1, dot_prod_scores.squeeze()[rank[i]]))\n",
    "  print(valid_corpus[rank[i]])\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lBaKYpdoXDcW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Dense Passage Retrieval (In-batch).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "169dfc0f181b4dd9bab8ea9eef8109cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8aabed3b5c5f4c099a7f3df1e4c4e006",
      "placeholder": "​",
      "style": "IPY_MODEL_440d4740d27f4f0595bb82b492d082b6",
      "value": "100%"
     }
    },
    "1a9a0ad91a494ae2aaaeb39ea7c55182": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a1392ec980ab4c68a01fcaf710973499",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_37d1ffffa4044912ba3fdfa2404536fe",
      "value": 2
     }
    },
    "37d1ffffa4044912ba3fdfa2404536fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "440d4740d27f4f0595bb82b492d082b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "58847f46ff934a57a2f652af23227814": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "746acc13c0434148997b2be1e5e347dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_169dfc0f181b4dd9bab8ea9eef8109cc",
       "IPY_MODEL_1a9a0ad91a494ae2aaaeb39ea7c55182",
       "IPY_MODEL_f813a93c66c9478190c4106545871b49"
      ],
      "layout": "IPY_MODEL_e694d87aed874031a16c282b33f5c2f4"
     }
    },
    "8aabed3b5c5f4c099a7f3df1e4c4e006": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a1392ec980ab4c68a01fcaf710973499": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ce610399056148c19cffca5073689e08": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e694d87aed874031a16c282b33f5c2f4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f813a93c66c9478190c4106545871b49": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ce610399056148c19cffca5073689e08",
      "placeholder": "​",
      "style": "IPY_MODEL_58847f46ff934a57a2f652af23227814",
      "value": " 2/2 [00:00&lt;00:00, 50.52it/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
